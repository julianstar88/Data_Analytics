{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import pathlib as pl\n",
    "import re\n",
    "import random\n",
    "import subprocess\n",
    "from icecream import ic\n",
    "\n",
    "import spacy\n",
    "# from spacy.util import minibatch, compounding\n",
    "import spacy.tokens\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "ic.configureOutput(includeContext=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(nlp: spacy.Language, labels: list[str], outfile: pl.Path, data:list) -> None:\n",
    "    db = spacy.tokens.DocBin()\n",
    "    docs = list()\n",
    "    \n",
    "    # convert data do DocBin\n",
    "    for doc, true_label in nlp.pipe(data, as_tuples=True):\n",
    "        cat_values = {label: False for label in labels}\n",
    "        cat_values[true_label] = True\n",
    "        doc.cats = cat_values\n",
    "        db.add(doc)\n",
    "\n",
    "    # save DocBin to disk\n",
    "    db.to_disk(outfile)\n",
    "    print(f\"worte '{outfile}'\")\n",
    "\n",
    "def extract_rating(row: str, which: str) -> int:\n",
    "    pattern = re.compile(r\"'{}':\\s?(\\d+\\.\\d+)\".format(which))\n",
    "    match_object = re.search(pattern, row)\n",
    "    if match_object:\n",
    "        rating = float(match_object.group(1))\n",
    "        rating = int(rating)\n",
    "        rating = str(rating)\n",
    "        return rating\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def make_predictions(text: str, nlp: spacy.Language) -> int:\n",
    "    doc = nlp(text)\n",
    "    cat_values = list(doc.cats.values())\n",
    "    cat_labels = list(doc.cats.keys())\n",
    "    rating = int(cat_labels[cat_values.index(max(cat_values))])\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting dataset for trainingdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date_stayed</th>\n",
       "      <th>offering_id</th>\n",
       "      <th>num_helpful_votes</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>via_mobile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'service': 5.0, 'cleanliness': 5.0, 'overall'...</td>\n",
       "      <td>“Truly is \"Jewel of the Upper Wets Side\"”</td>\n",
       "      <td>Stayed in a king suite for 11 nights and yes i...</td>\n",
       "      <td>{'username': 'Papa_Panda', 'num_cities': 22, '...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>93338</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>147643103</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'service': 5.0, 'cleanliness': 5.0, 'overall'...</td>\n",
       "      <td>“My home away from home!”</td>\n",
       "      <td>On every visit to NYC, the Hotel Beacon is the...</td>\n",
       "      <td>{'username': 'Maureen V', 'num_reviews': 2, 'n...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>93338</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>147639004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'service': 4.0, 'cleanliness': 5.0, 'overall'...</td>\n",
       "      <td>“Great Stay”</td>\n",
       "      <td>This is a great property in Midtown. We two di...</td>\n",
       "      <td>{'username': 'vuguru', 'num_cities': 12, 'num_...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>1762573</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>147697954</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'service': 5.0, 'cleanliness': 5.0, 'overall'...</td>\n",
       "      <td>“Modern Convenience”</td>\n",
       "      <td>The Andaz is a nice hotel in a central locatio...</td>\n",
       "      <td>{'username': 'Hotel-Designer', 'num_cities': 5...</td>\n",
       "      <td>August 2012</td>\n",
       "      <td>1762573</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>147625723</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'service': 4.0, 'cleanliness': 5.0, 'overall'...</td>\n",
       "      <td>“Its the best of the Andaz Brand in the US....”</td>\n",
       "      <td>I have stayed at each of the US Andaz properti...</td>\n",
       "      <td>{'username': 'JamesE339', 'num_cities': 34, 'n...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>1762573</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>147612823</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ratings  \\\n",
       "0  {'service': 5.0, 'cleanliness': 5.0, 'overall'...   \n",
       "1  {'service': 5.0, 'cleanliness': 5.0, 'overall'...   \n",
       "2  {'service': 4.0, 'cleanliness': 5.0, 'overall'...   \n",
       "3  {'service': 5.0, 'cleanliness': 5.0, 'overall'...   \n",
       "4  {'service': 4.0, 'cleanliness': 5.0, 'overall'...   \n",
       "\n",
       "                                             title  \\\n",
       "0        “Truly is \"Jewel of the Upper Wets Side\"”   \n",
       "1                        “My home away from home!”   \n",
       "2                                     “Great Stay”   \n",
       "3                             “Modern Convenience”   \n",
       "4  “Its the best of the Andaz Brand in the US....”   \n",
       "\n",
       "                                                text  \\\n",
       "0  Stayed in a king suite for 11 nights and yes i...   \n",
       "1  On every visit to NYC, the Hotel Beacon is the...   \n",
       "2  This is a great property in Midtown. We two di...   \n",
       "3  The Andaz is a nice hotel in a central locatio...   \n",
       "4  I have stayed at each of the US Andaz properti...   \n",
       "\n",
       "                                              author    date_stayed  \\\n",
       "0  {'username': 'Papa_Panda', 'num_cities': 22, '...  December 2012   \n",
       "1  {'username': 'Maureen V', 'num_reviews': 2, 'n...  December 2012   \n",
       "2  {'username': 'vuguru', 'num_cities': 12, 'num_...  December 2012   \n",
       "3  {'username': 'Hotel-Designer', 'num_cities': 5...    August 2012   \n",
       "4  {'username': 'JamesE339', 'num_cities': 34, 'n...  December 2012   \n",
       "\n",
       "   offering_id  num_helpful_votes        date         id  via_mobile  \n",
       "0        93338                  0  2012-12-17  147643103       False  \n",
       "1        93338                  0  2012-12-17  147639004       False  \n",
       "2      1762573                  0  2012-12-18  147697954       False  \n",
       "3      1762573                  0  2012-12-17  147625723       False  \n",
       "4      1762573                  0  2012-12-17  147612823       False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = pl.Path(r\"C:\\Users\\milit\\Documents\\python\\Data_Analytics\\ProjectWoche\\Data\\trip_advisor_reviews.zip\")\n",
    "data = pd.read_csv(file_path, compression=\"zip\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring for data important for training\n",
    "- ratings: extracted overall\n",
    "- text\n",
    "\n",
    "- explore missing values of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploring missing values for cols 'ratings' and 'text'\n",
      "missing values ratings: 0.0%\n",
      "missing values text: 0.0%\n"
     ]
    }
   ],
   "source": [
    "train_df = data[[\"ratings\", \"text\"]]\n",
    "\n",
    "# extract the overall rating from ratings\n",
    "train_df[\"overall_rating\"] = train_df[\"ratings\"].apply(extract_rating, args=(\"overall\",))\n",
    "\n",
    "# data exploration\n",
    "missing_values_text = train_df[train_df[\"text\"].isna()]\n",
    "missing_values_ratings = train_df[train_df[\"ratings\"].isna()]\n",
    "print(\"exploring missing values for cols 'ratings' and 'text'\")\n",
    "print(f\"missing values ratings: {missing_values_ratings.shape[0] / train_df['text'].shape[0]}%\")\n",
    "print(f\"missing values text: {missing_values_text.shape[0] / train_df['text'].shape[0]}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>pedicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>Jihae</td>\n",
       "      <td>Karin’s “Aplace” is absolutely beautiful and c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-10</td>\n",
       "      <td>Emilie</td>\n",
       "      <td>Karin is a wonderful host, she was really help...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>Marie-Lou</td>\n",
       "      <td>The location is super super nice! Karin was al...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-02-20</td>\n",
       "      <td>Hiske &amp; Erik</td>\n",
       "      <td>Perfect location for exploring the city, close...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-03-05</td>\n",
       "      <td>Paolo</td>\n",
       "      <td>Muriel was such a fantastic host, extremely he...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date reviewer_name  \\\n",
       "0  2015-05-06         Jihae   \n",
       "1  2021-10-10        Emilie   \n",
       "2  2022-05-15     Marie-Lou   \n",
       "3  2012-02-20  Hiske & Erik   \n",
       "4  2012-03-05         Paolo   \n",
       "\n",
       "                                            comments  pedicted_rating  \n",
       "0  Karin’s “Aplace” is absolutely beautiful and c...              NaN  \n",
       "1  Karin is a wonderful host, she was really help...              NaN  \n",
       "2  The location is super super nice! Karin was al...              NaN  \n",
       "3  Perfect location for exploring the city, close...              NaN  \n",
       "4  Muriel was such a fantastic host, extremely he...              NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = pl.Path(r\"C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\data\\cities\\reviews_antwerp.csv.gz\")\n",
    "prediction_data_raw = pd.read_csv(file_path, compression=\"gzip\")\n",
    "prediction_data = prediction_data_raw[[\"date\", \"reviewer_name\", \"comments\"]]\n",
    "prediction_data[\"pedicted_rating\"] = prediction_data.apply(lambda row: -1)\n",
    "prediction_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore predictiondata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102902, 4)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train spacy from CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup spacy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create base_config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: textcat\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_config\\base_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train base_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "config_path = pl.Path(r\"C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_config\")\n",
    "base_config_file = pl.Path(\"base_config.cfg\")\n",
    "!python -m spacy init config {config_path/base_config_file} --pipeline textcat --optimize efficiency --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create config.cfg from base_config.cfg and fill with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ Nothing to auto-fill: base config is already complete\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_config\\config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "config_file = pl.Path(\"config.cfg\")\n",
    "!python -m spacy init fill-config {config_path/base_config_file} {config_path/config_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train data: 7\n",
      "len dev data: 2\n",
      "len test data: 1\n",
      "worte 'C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_train\\train.spacy'\n",
      "worte 'C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_train\\dev.spacy'\n",
      "worte 'C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_train\\test.spacy'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milit\\AppData\\Local\\Temp\\ipykernel_20704\\2426643275.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"overall_rating\"] = train_df[\"ratings\"].apply(extract_rating, args=(\"overall\",))\n"
     ]
    }
   ],
   "source": [
    "train_path = pl.Path(r\"C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_train\")\n",
    "train_file = pl.Path(\"train.spacy\")\n",
    "dev_file = pl.Path(\"dev.spacy\")\n",
    "test_file = pl.Path(\"test.spacy\")\n",
    "labels = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "train_split = 0.75\n",
    "dev_split = 0.9\n",
    "\n",
    "# get a random sample from original data for testing purpose\n",
    "sample_data = train_df.sample(n=10, axis=0)\n",
    "\n",
    "# convert data to list and shuffle the data\n",
    "sample_data = list(\n",
    "    sample_data[[\"text\", \"overall_rating\"]].sample(frac=1).itertuples(index=False, name=None)\n",
    ")\n",
    "\n",
    "# split the data into training-, evaluation-, and testdata\n",
    "\n",
    "train_split = int(train_split * len(sample_data))\n",
    "dev_split = int(dev_split * len(sample_data))\n",
    "train_data = sample_data[:train_split]\n",
    "dev_data = sample_data[train_split:dev_split]\n",
    "test_data = sample_data[dev_split:]\n",
    "print(f\"len train data: {len(train_data)}\")\n",
    "print(f\"len dev data: {len(dev_data)}\")\n",
    "print(f\"len test data: {len(test_data)}\")\n",
    "\n",
    "\n",
    "# convert training data\n",
    "convert_data(\n",
    "    nlp=nlp,\n",
    "    labels=labels,\n",
    "    outfile=train_path / train_file, \n",
    "    data=train_data, \n",
    ")\n",
    "\n",
    "# convert dev data\n",
    "convert_data(\n",
    "    nlp=nlp,\n",
    "    labels=labels,\n",
    "    outfile=train_path / dev_file, \n",
    "    data=dev_data, \n",
    ")\n",
    "\n",
    "# convert test data\n",
    "convert_data(\n",
    "    nlp=nlp,\n",
    "    labels=labels,\n",
    "    outfile=train_path / test_file, \n",
    "    data=test_data, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.16       13.33    0.13\n",
      " 28     200          2.23        0.00    0.00\n",
      " 60     400          0.01        0.00    0.00\n",
      " 93     600          0.00        0.00    0.00\n",
      "126     800          0.00        0.00    0.00\n",
      "157    1000          0.00        0.00    0.00\n",
      "188    1200          0.00        0.00    0.00\n",
      "218    1400          0.00        0.00    0.00\n",
      "251    1600          0.00        0.00    0.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_model\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-18 00:46:20,613] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "[2024-06-18 00:46:20,855] [INFO] Set up nlp object from config\n",
      "[2024-06-18 00:46:20,869] [DEBUG] Loading corpus from path: C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_train\\dev.spacy\n",
      "[2024-06-18 00:46:20,870] [DEBUG] Loading corpus from path: C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_train\\train.spacy\n",
      "[2024-06-18 00:46:20,870] [INFO] Pipeline: ['textcat']\n",
      "[2024-06-18 00:46:20,874] [INFO] Created vocabulary\n",
      "[2024-06-18 00:46:20,874] [INFO] Finished initializing nlp object\n",
      "[2024-06-18 00:46:20,943] [INFO] Initialized pipeline components: ['textcat']\n",
      "[2024-06-18 00:46:20,956] [DEBUG] Loading corpus from path: C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_train\\dev.spacy\n",
      "[2024-06-18 00:46:20,957] [DEBUG] Loading corpus from path: C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_train\\train.spacy\n",
      "[2024-06-18 00:46:20,963] [DEBUG] Removed existing output directory: C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_model\\model-best\n",
      "[2024-06-18 00:46:20,968] [DEBUG] Removed existing output directory: C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_model\\model-last\n"
     ]
    }
   ],
   "source": [
    "output_path = pl.Path(r\"C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_model\")\n",
    "!python -m spacy train {config_path/config_file} --paths.train {train_path/train_file} --paths.dev {train_path/dev_file} --output {output_path} --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   0.00  \n",
      "SPEED               24125 \n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "       P      R      F\n",
      "1   0.00   0.00   0.00\n",
      "2   0.00   0.00   0.00\n",
      "3   0.00   0.00   0.00\n",
      "4   0.00   0.00   0.00\n",
      "5   0.00   0.00   0.00\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "    ROC AUC\n",
      "1      None\n",
      "2      None\n",
      "3      None\n",
      "4      None\n",
      "5      None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = pl.Path(r\"C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_model\")\n",
    "model_file = pl.Path(\"model-best\")\n",
    "!python -m spacy benchmark accuracy {model_path/model_file} {train_path/test_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pedict rating for good texts\n",
      "rating: {'1': 0.1240428164601326, '2': 0.20191678404808044, '3': 0.240362286567688, '4': 0.212214395403862, '5': 0.22146371006965637} -- text: this is a very beautiful place for a stay in this lovely city\n",
      "pedict rating for bad texts\n",
      "rating: {'1': 0.18104076385498047, '2': 0.19354777038097382, '3': 0.21970169246196747, '4': 0.21357141435146332, '5': 0.19213831424713135} -- text: A really, really terrible place \n"
     ]
    }
   ],
   "source": [
    "# load the model with highest accuracy\n",
    "nlp = spacy.load(r\"C:\\Users\\milit\\Desktop\\Alfatraining\\Data_Scientist\\02_Data_Analytics\\04_Projekt_Woche\\spacy_model\\model-last\")\n",
    "\n",
    "# test a simple expression before predicting AirBnB-ratings\n",
    "texts_good = [\"this is a very beautiful place for a stay in this lovely city\"]\n",
    "texts_bad = [\"A really, really terrible place \"]\n",
    "\n",
    "print(\"pedict rating for good texts\")\n",
    "for text in texts_good:\n",
    "    doc = nlp(text)\n",
    "    print(f\"rating: {doc.cats} -- text: {text}\")\n",
    "\n",
    "print(\"pedict rating for bad texts\")\n",
    "for text in texts_bad:\n",
    "    doc = nlp(text)\n",
    "    print(f\"rating: {doc.cats} -- text: {text}\")\n",
    "\n",
    "\n",
    "# finally predict the AirBnB ratings\n",
    "\n",
    "\n",
    "prediction_sample = prediction_data.sample(n=100, axis=0)\n",
    "prediction_sample[\"pedicted_rating\"] = prediction_sample[\"comments\"].apply(make_predictions, args=(nlp,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
